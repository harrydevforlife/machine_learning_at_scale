{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Hướng dẫn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Khởi tạo Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "findspark.find()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count\n",
    "\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .appName(\"Classification and Regression\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Đọc và load tập dữ liệu Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-----------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|      class|\n",
      "+------------+-----------+------------+-----------+-----------+\n",
      "|         5.1|        3.5|         1.4|        0.2|Iris-setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2|Iris-setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2|Iris-setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2|Iris-setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2|Iris-setosa|\n",
      "+------------+-----------+------------+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "irisDF = (spark.read\n",
    "          .option(\"HEADER\", True)\n",
    "          .option(\"inferSchema\", True)\n",
    "          .csv(\"./data/iris.csv\")\n",
    "         )\n",
    "\n",
    "irisDF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chuyển cột `class` (kiểu string) thành `label` (kiểu double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-----------+-----+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|      class|label|\n",
      "+------------+-----------+------------+-----------+-----------+-----+\n",
      "|         5.1|        3.5|         1.4|        0.2|Iris-setosa|  0.0|\n",
      "|         4.9|        3.0|         1.4|        0.2|Iris-setosa|  0.0|\n",
      "|         4.7|        3.2|         1.3|        0.2|Iris-setosa|  0.0|\n",
      "|         4.6|        3.1|         1.5|        0.2|Iris-setosa|  0.0|\n",
      "|         5.0|        3.6|         1.4|        0.2|Iris-setosa|  0.0|\n",
      "+------------+-----------+------------+-----------+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "class_indexer = StringIndexer(inputCol = 'class', outputCol = 'label')\n",
    "\n",
    "irisDFindexed = class_indexer.fit(irisDF).transform(irisDF)\n",
    "\n",
    "irisDFindexed.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tập dữ liệu Iris\n",
    "\n",
    "`sepal_length`: chiều dài đài hoa (cm)\n",
    "\n",
    "`sepal_width`: chiều rộng đài hoa (cm)\n",
    "\n",
    "`petal_length`: chiều dài cánh hoa (cm)\n",
    "\n",
    "`petal_width`: chiều rộng cánh hoa (cm)\n",
    "\n",
    "`class/label`: loại hoa\n",
    "\n",
    "![Iris dataset](./image/iris.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chia dữ liệu thành train/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainDF, testDF) = irisDFindexed.randomSplit([.8, .2], seed = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xem các loại biến trong tập dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sepal_length', 'double'),\n",
       " ('sepal_width', 'double'),\n",
       " ('petal_length', 'double'),\n",
       " ('petal_width', 'double'),\n",
       " ('class', 'string'),\n",
       " ('label', 'double')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisDFindexed.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biến đổi train data và test data theo định dạng của Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|         features|label|\n",
      "+-----------------+-----+\n",
      "|[4.3,3.0,1.1,0.1]|  0.0|\n",
      "|[4.4,2.9,1.4,0.2]|  0.0|\n",
      "|[4.4,3.0,1.3,0.2]|  0.0|\n",
      "|[4.4,3.2,1.3,0.2]|  0.0|\n",
      "|[4.6,3.1,1.5,0.2]|  0.0|\n",
      "+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols = ['sepal_length','sepal_width','petal_length','petal_width'],\n",
    "                            outputCol = 'features')\n",
    "assembler_train = assembler.transform(trainDF)\n",
    "\n",
    "X_train = assembler_train.select('features', 'label')\n",
    "X_train.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sử dụng Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Tạo mô hình Logistic Regression\n",
    "\n",
    "Tạo một một hình Logistic Regression và huấn luyện mô hình trên `X_train` với `labelCol` là `'label'` và `featuresCol` là `'features'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "logit = LogisticRegression(featuresCol = \"features\", labelCol = \"label\")\n",
    "\n",
    "logitModel = logit.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Áp dụng mô hình trên test data\n",
    "\n",
    "Áp dụng biến đổi cho tập test tương tự như trên tập train. In ra vài dòng sau khi biến đổi để xem kết quả."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|         features|label|\n",
      "+-----------------+-----+\n",
      "|[4.5,2.3,1.3,0.3]|  0.0|\n",
      "|[4.8,3.1,1.6,0.2]|  0.0|\n",
      "|[4.8,3.4,1.6,0.2]|  0.0|\n",
      "|[4.8,3.4,1.9,0.2]|  0.0|\n",
      "|[4.9,2.5,4.5,1.7]|  2.0|\n",
      "+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembler_test = assembler.transform(testDF)\n",
    "X_test = assembler_test.select('features', 'label')\n",
    "X_test.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dự đoán trên test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|label|\n",
      "+----------+-----+\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       0.0|  0.0|\n",
      "|       1.0|  2.0|\n",
      "+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = logitModel.transform(X_test)\n",
    "predictions.select(\"prediction\", \"label\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Đánh giá mô hình\n",
    "\n",
    "Tính giá trị `Accuracy` của mô hình trên tập test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.961538\n",
      "Test Error = 0.0384615\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator()\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\n",
    "print(\"Accuracy = %g\" % accuracy)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Tạo ML pipeline và đánh giá dùng phương pháp cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'features=[4.5,2.3,1.3,0.3], label=2.0 -> prediction=2.0'\n",
      "'features=[4.8,3.1,1.6,0.2], label=2.0 -> prediction=2.0'\n",
      "'features=[4.8,3.4,1.6,0.2], label=2.0 -> prediction=2.0'\n",
      "'features=[4.8,3.4,1.9,0.2], label=2.0 -> prediction=2.0'\n",
      "'features=[4.9,2.5,4.5,1.7], label=1.0 -> prediction=0.0'\n",
      "Test Error = 0.0384615\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent = 4)\n",
    "\n",
    "# Create a LogisticRegression instance. This instance is an Estimator.\n",
    "logit = LogisticRegression(featuresCol = \"features\", labelCol = \"label\")\n",
    "\n",
    "# Define indexer\n",
    "indexer = StringIndexer(inputCol = 'class', \n",
    "                        outputCol = 'label')\n",
    "\n",
    "# Define assembler\n",
    "assembler = VectorAssembler(inputCols = ['sepal_length','sepal_width','petal_length','petal_width'],\n",
    "                            outputCol = 'features')\n",
    "\n",
    "# Configure an ML pipeline, which consists of two stages: indexer, assembler, and logit.\n",
    "pipeline = Pipeline(stages = [indexer, assembler, logit])\n",
    "\n",
    "# Specify evaluator\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol = \"label\", \n",
    "    predictionCol = \"prediction\",\n",
    "    metricName = \"accuracy\"\n",
    ")\n",
    "\n",
    "# Specify parameters\n",
    "paramGrid = (ParamGridBuilder()\n",
    "            .addGrid(logit.regParam , [0.01, 0.1, 1])\n",
    "            .build())\n",
    "\n",
    "# Train/test split\n",
    "(trainDF, testDF) = irisDF.randomSplit([.8, .2], seed = 1)\n",
    "\n",
    "# Setup CrossValidator \n",
    "# A CrossValidator requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n",
    "cv = CrossValidator(estimator = logit, \n",
    "                    evaluator = evaluator, \n",
    "                    estimatorParamMaps = paramGrid, \n",
    "                    numFolds = 3, \n",
    "                    parallelism = 2, \n",
    "                    seed = 1)\n",
    "\n",
    "# Run cross-validation on training data, and choose the best set of parameters\n",
    "logitModel = pipeline.fit(trainDF)\n",
    "\n",
    "# Make predictions on test data. logitModel uses the best model found (regParam = 0.1)\n",
    "prediction = logitModel.transform(testDF)\n",
    "result = prediction.select(\"features\", \"label\", \"prediction\").collect()\n",
    "\n",
    "# Print some predictions\n",
    "for row in result[0:5]:\n",
    "    pp.pprint(\"features=%s, label=%s -> prediction=%s\" % \n",
    "              (row.features, row.label, row.prediction))\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Áp dụng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Câu 1 - Áp dụng `LogisticRegression` với tập dữ liệu `Auto`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Câu hỏi này sử dụng Logistic Regression trên tập dữ liệu `Auto` để dự đoán một xe cho trước có `mpg` là `high` hay `low`.\n",
    "\n",
    "**Auto Data Set Description**\n",
    "\n",
    "A data frame with 392 observations on the following 9 variables.\n",
    "\n",
    "- `mpg`: miles per gallon\n",
    "\n",
    "- `cylinders`: Number of cylinders between 4 and 8\n",
    "\n",
    "- `displacement`: Engine displacement (cu. inches)\n",
    "\n",
    "- `horsepower`: Engine horsepower\n",
    "\n",
    "- `weight`: Vehicle weight (lbs.)\n",
    "\n",
    "- `acceleration`: Time to accelerate from 0 to 60 mph (sec.)\n",
    "\n",
    "- `year`: Model year (modulo 100)\n",
    "\n",
    "- `origin`: Origin of car (1. American, 2. European, 3. Japanese)\n",
    "\n",
    "- `name`: Vehicle name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1.** Tạo một binary variable nhận giá trị 1 (`high`) với các xe có `mpg` lớn hơn median mpg, và nhận giá trị 0 (`low`) cho các xe còn lại."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viết code của bạn ở đây\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2.** Áp dụng Logistic Regression cho tập dữ liệu với các giá trị siêu tham số `regParam` khác nhau để dự đoán `mpg`. Cho biết cross-validation error ứng với các giá trị khác nhau của siêu tham số này. Nhận xét kết quả thu được. Tham khảo document về Logistic Regression của Spark ở [LogisticRegression](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.classification.LogisticRegression.html#pyspark.ml.classification.LogisticRegression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viết code của bạn ở đây\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Câu 2 - So sánh các mô hình phân loại"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thực hiện việc train tất cả các mô hình `LogisticRegression`, `DecisionTreeClassifier` và `RandomForestClassifier`, `GBTClassifier`, `MultilayerPerceptronClassifier`, `LinearSVC`, `NaiveBayes` trên tập dữ liệu HeartDisease (https://archive.ics.uci.edu/ml/datasets/heart+Disease). Điều chỉnh các siêu tham số của các mô hình để chọn mô hình tốt nhất dùng cross validation. So sánh và nhận xét về kết quả của các mô hình. Để tránh lặp lại các bước xử lý giống nhau nhiều lần như ở trên bạn nên tạo pipeline các bước xử lý. Tham khảo cách tạo pipeline cho mô hình ở [đây](https://spark.apache.org/docs/latest/ml-pipeline.html). Tham khảo document về các classifier của Spark ở [classification module](https://spark.apache.org/docs/latest/api/python/reference/pyspark.ml.html#classification).\n",
    "\n",
    "Bên dưới là một số gợi ý."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+------------+------+----+---+-------+-----+-----+-------+-----+---+----------+---+\n",
      "|_c0|Age|Sex|   ChestPain|RestBP|Chol|Fbs|RestECG|MaxHR|ExAng|Oldpeak|Slope| Ca|      Thal|AHD|\n",
      "+---+---+---+------------+------+----+---+-------+-----+-----+-------+-----+---+----------+---+\n",
      "|  1| 63|  1|     typical|   145| 233|  1|      2|  150|    0|    2.3|    3|  0|     fixed| No|\n",
      "|  2| 67|  1|asymptomatic|   160| 286|  0|      2|  108|    1|    1.5|    2|  3|    normal|Yes|\n",
      "|  3| 67|  1|asymptomatic|   120| 229|  0|      2|  129|    1|    2.6|    2|  2|reversable|Yes|\n",
      "|  4| 37|  1|  nonanginal|   130| 250|  0|      0|  187|    0|    3.5|    3|  0|    normal| No|\n",
      "|  5| 41|  0|  nontypical|   130| 204|  0|      2|  172|    0|    1.4|    1|  0|    normal| No|\n",
      "+---+---+---+------------+------+----+---+-------+-----+-----+-------+-----+---+----------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heart = (spark.read\n",
    "          .option(\"HEADER\", True)\n",
    "          .option(\"inferSchema\", True)\n",
    "          .csv(\"./data/HeartDisease.csv\")\n",
    "         )\n",
    "\n",
    "heart.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(heart.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_c0', 'int'),\n",
       " ('Age', 'int'),\n",
       " ('Sex', 'int'),\n",
       " ('ChestPain', 'string'),\n",
       " ('RestBP', 'int'),\n",
       " ('Chol', 'int'),\n",
       " ('Fbs', 'int'),\n",
       " ('RestECG', 'int'),\n",
       " ('MaxHR', 'int'),\n",
       " ('ExAng', 'int'),\n",
       " ('Oldpeak', 'double'),\n",
       " ('Slope', 'int'),\n",
       " ('Ca', 'string'),\n",
       " ('Thal', 'string'),\n",
       " ('AHD', 'string')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: int, Age: int, Sex: int, ChestPain: string, RestBP: int, Chol: int, Fbs: int, RestECG: int, MaxHR: int, ExAng: int, Oldpeak: double, Slope: int, Ca: int, Thal: string, AHD: string]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart.withColumn('Ca', heart.Ca.cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+-----+----------+-------------+-------------+-------------+-------------+\n",
      "|   ChestPain|RestECG|Slope|      Thal| ChestPainOHE|   RestECGOHE|     SlopeOHE|      ThalOHE|\n",
      "+------------+-------+-----+----------+-------------+-------------+-------------+-------------+\n",
      "|     typical|      2|    3|     fixed|    (3,[],[])|(2,[1],[1.0])|    (2,[],[])|(3,[2],[1.0])|\n",
      "|asymptomatic|      2|    2|    normal|(3,[0],[1.0])|(2,[1],[1.0])|(2,[1],[1.0])|(3,[0],[1.0])|\n",
      "|asymptomatic|      2|    2|reversable|(3,[0],[1.0])|(2,[1],[1.0])|(2,[1],[1.0])|(3,[1],[1.0])|\n",
      "|  nonanginal|      0|    3|    normal|(3,[1],[1.0])|(2,[0],[1.0])|    (2,[],[])|(3,[0],[1.0])|\n",
      "|  nontypical|      2|    1|    normal|(3,[2],[1.0])|(2,[1],[1.0])|(2,[0],[1.0])|(3,[0],[1.0])|\n",
      "+------------+-------+-----+----------+-------------+-------------+-------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "catInputCols = ['ChestPain', 'RestECG', 'Slope', 'Thal']\n",
    "catOutputCols = [x + \"Index\" for x in catInputCols]\n",
    "oheCatOutputCols = [x + \"OHE\" for x in catInputCols]\n",
    "\n",
    "catIndexer = StringIndexer(inputCols = catInputCols, outputCols = catOutputCols)\n",
    "\n",
    "catOHEncoder = OneHotEncoder(inputCols = catOutputCols, \n",
    "                          outputCols = oheCatOutputCols)\n",
    "\n",
    "pipeline = Pipeline(stages = [catIndexer, catOHEncoder])\n",
    "\n",
    "# fit the pipeline model and transform the data as defined\n",
    "pipelineModel = pipeline.fit(heart)\n",
    "\n",
    "# view the transformed data\n",
    "transformed_heart = pipelineModel.transform(heart)\n",
    "transformed_heart.select(catInputCols + oheCatOutputCols).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viết code của bạn ở đây\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Câu 3 - So sánh các mô hình hồi quy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thực hiện việc train tất cả các mô hình `LinearRegression`, `DecisionTreeRegression` và `RandomForestRegression`, `GBTRegression` trên tập một tập dữ liệu cho bài toán hồi quy (có 10-100 thuộc tính gồm cả thuộc tính phân loại và thuộc tính số và có 100-1000 đối tượng) mà bạn quan tâm ở [UCI Regression Dataset](https://archive.ics.uci.edu/ml/datasets.php?format=&task=reg&att=&area=&numAtt=10to100&numIns=100to1000&type=&sort=nameUp&view=table). Điều chỉnh các siêu tham số của các mô hình để chọn mô hình tốt nhất dùng cross validation. Để tránh lặp lại các bước xử lý giống nhau nhiều lần như ở trên bạn nên tạo pipeline các bước xử lý. Tham khảo cách tạo pipeline cho mô hình ở [đây](https://spark.apache.org/docs/latest/ml-pipeline.html). Tham khảo document về các classifier của Spark ở [regression module](https://spark.apache.org/docs/latest/api/python/reference/pyspark.ml.html#regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viết code của bạn ở đây\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
