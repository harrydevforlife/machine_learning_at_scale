{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3 - Linear Regression\n",
    "\n",
    "\n",
    "- Your name: Trần Công Tuấn Mạnh\n",
    "\n",
    "- Your student code: 19133035"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Hướng dẫn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Khởi tạo Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "findspark.find()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count\n",
    "\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .appName(\"Linear Regression\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Đọc và load tập dữ liệu Boston housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+\n",
      "|   crim|  zn|indus|chas|  nox|   rm| age|   dis|rad|tax|ptratio|     b|lstat|medv|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+\n",
      "|0.00632|18.0| 2.31|   0|0.538|6.575|65.2|  4.09|  1|296|   15.3| 396.9| 4.98|24.0|\n",
      "|0.02731| 0.0| 7.07|   0|0.469|6.421|78.9|4.9671|  2|242|   17.8| 396.9| 9.14|21.6|\n",
      "|0.02729| 0.0| 7.07|   0|0.469|7.185|61.1|4.9671|  2|242|   17.8|392.83| 4.03|34.7|\n",
      "|0.03237| 0.0| 2.18|   0|0.458|6.998|45.8|6.0622|  3|222|   18.7|394.63| 2.94|33.4|\n",
      "|0.06905| 0.0| 2.18|   0|0.458|7.147|54.2|6.0622|  3|222|   18.7| 396.9| 5.33|36.2|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bostonDF = (spark.read\n",
    "            .option(\"HEADER\", True)\n",
    "            .option(\"inferSchema\", True)\n",
    "            .csv(\"BostonHousing.csv\")\n",
    "           )\n",
    "\n",
    "bostonDF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Giới thiệu tập dữ liệu Boston housing\n",
    "\n",
    "`crim`: per capita crime rate by town.\n",
    "\n",
    "`zn`: proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "\n",
    "`indus`: proportion of non-retail business acres per town.\n",
    "\n",
    "`chas`: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).\n",
    "\n",
    "`nox`: nitrogen oxides concentration (parts per 10 million).\n",
    "\n",
    "`rm`: average number of rooms per dwelling.\n",
    "\n",
    "`age`: proportion of owner-occupied units built prior to 1940.\n",
    "\n",
    "`dis`: weighted mean of distances to five Boston employment centres.\n",
    "\n",
    "`rad`: index of accessibility to radial highways.\n",
    "\n",
    "`tax`: full-value property-tax rate per 10,000 dollars.\n",
    "\n",
    "`ptratio`: pupil-teacher ratio by town.\n",
    "\n",
    "`b` (`black`): $1000(Bk - 0.63)^2$ where $Bk$ is the proportion of blacks by town.\n",
    "\n",
    "`lstat`: lower status of the population (percent).\n",
    "\n",
    "`medv`: median value of owner-occupied homes in 1000 dollars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Tạo các biến input (features) và output (label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark khác với nhiều machine learning framework khác ở chỗ ta cần huấn luyện mô hình của mình trên một cột duy nhất có chứa một vectơ gồm tất cả các feature (attribute) mà ta quan tâm. Ta sẽ chuẩn bị dữ liệu bằng cách tạo một cột có tên `features` gồm các thuộc tính `rm` (average number of rooms), `crim` (crime rate),  và `lstat` (lower status of the population).\n",
    "\n",
    "Thêm cột `features` vừa tạo vào data frame sử dụng `VectorAssembler`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+--------------------+\n",
      "|   crim|  zn|indus|chas|  nox|   rm| age|   dis|rad|tax|ptratio|     b|lstat|medv|            features|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+--------------------+\n",
      "|0.00632|18.0| 2.31|   0|0.538|6.575|65.2|  4.09|  1|296|   15.3| 396.9| 4.98|24.0|[6.575,0.00632,4.98]|\n",
      "|0.02731| 0.0| 7.07|   0|0.469|6.421|78.9|4.9671|  2|242|   17.8| 396.9| 9.14|21.6|[6.421,0.02731,9.14]|\n",
      "|0.02729| 0.0| 7.07|   0|0.469|7.185|61.1|4.9671|  2|242|   17.8|392.83| 4.03|34.7|[7.185,0.02729,4.03]|\n",
      "|0.03237| 0.0| 2.18|   0|0.458|6.998|45.8|6.0622|  3|222|   18.7|394.63| 2.94|33.4|[6.998,0.03237,2.94]|\n",
      "|0.06905| 0.0| 2.18|   0|0.458|7.147|54.2|6.0622|  3|222|   18.7| 396.9| 5.33|36.2|[7.147,0.06905,5.33]|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "featureCols = [\"rm\", \"crim\", \"lstat\"]\n",
    "assembler = VectorAssembler(inputCols = featureCols, outputCol = \"features\")\n",
    "bostonFeaturizedDF = assembler.transform(bostonDF)\n",
    "\n",
    "bostonFeaturizedDF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Tạo mô hình Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import thư viện linear regression và thiết lập output là thuộc tính `medv`, input là `features`. Tham khảo thêm về các tham số của thư viện LinearRegression ở [đây](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.LinearRegression.html#pyspark.ml.regression.LinearRegression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(labelCol = \"medv\", featuresCol = \"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. Fit mô hình với data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrModel = lr.fit(bostonFeaturizedDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7. Xem các tham số của mô hình sau khi đã fit với data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: 5.2, -0.1, -0.6\n",
      "Intercept: -2.6\n"
     ]
    }
   ],
   "source": [
    "print(\"Coefficients: {0:.1f}, {1:.1f}, {2:.1f}\".format(*lrModel.coefficients))\n",
    "print(\"Intercept: {0:.1f}\".format(lrModel.intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ý nghĩa**: $predicted\\_medv = (5.2 * rm) - (0.1 * crim) - (0.6 * lstat) - 2.6$\n",
    "\n",
    "hay $predicted\\_medv = (5.2 * number\\_of\\_rooms) - (0.1 * crime\\_rate) - (0.6 * lower\\_class) - 2.6$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hai độ đo đánh giá thường được dùng là Root Mean Squared Error (RMSE) và R-Squared score ($R^2$).\n",
    "\n",
    "$$RMSE(y, \\hat{y}) = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y_i})^2}$$\n",
    "\n",
    "$$R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y_i})^2}{\\sum_{i=1}^{n} (y_i - \\overline{y})^2}$$\n",
    "\n",
    "Trong đó:\n",
    "\n",
    "- $\\hat{y_i}$ là giá trị mà mô hình cho $x_i$\n",
    "    \n",
    "- $y_i$ là output thật sự cho $x_i$\n",
    "    \n",
    "- $n$ là số lượng phần tử trong dữ liệu\n",
    "    \n",
    "- $\\overline{y} = \\frac{1}{n} \\sum_{i=1}^{n} y_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Squared score: 0.6458520515781128\n"
     ]
    }
   ],
   "source": [
    "print(\"R-Squared score: {}\".format(lrModel.summary.r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ý nghĩa**: mô hình có thể giải thích khoảng $65 \\%$ sự biến thiên (variance) trong dữ liệu. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Một số độ đo và chỉ số khác:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE score: 3.8912949765069516\n",
      "RMSE score: 5.4678160740273904\n",
      "Coefficient Standard Errors: [0.44203471513494264, 0.03202221602654323, 0.047669471406803186, 3.1660227928472824]\n",
      "T Values: [11.802138487700892, -3.214670921988166, -12.135352093519266, -0.8092964515972317]\n",
      "P Values: [0.0, 0.0013900026454838343, 0.0, 0.41872805807608815]\n"
     ]
    }
   ],
   "source": [
    "lrModelSummary = lrModel.summary\n",
    "\n",
    "print(\"MAE score: {}\".format(lrModelSummary.meanAbsoluteError))\n",
    "print(\"RMSE score: {}\".format(lrModelSummary.rootMeanSquaredError))\n",
    "print(\"Coefficient Standard Errors: \" + str(lrModelSummary.coefficientStandardErrors))\n",
    "print(\"T Values: \" + str(lrModelSummary.tValues))\n",
    "print(\"P Values: \" + str(lrModelSummary.pValues))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Các chỉ số `Standard Errors`, `t-values`, `p-values` liên quan đến ý nghĩa thống kê (statistically significant) của các hệ số (tham số) của mô hình. Xem thêm về diễn giải của các chỉ số này ở [đây](https://dss.princeton.edu/online_help/analysis/interpreting_regression.htm) hoặc [đây](https://boostedml.com/2019/06/linear-regression-in-r-interpreting-summarylm.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8. Sử dụng mô hình\n",
    "\n",
    "Chọn ra 10 dòng dữ liệu đầu tiên (xem như nó là dữ liệu mới). Ta sẽ xem dự đoán của mô hình trên 10 dòng dữ liệu này và cho sánh nó với giá trị thực tế."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|            features|medv|\n",
      "+--------------------+----+\n",
      "|[6.575,0.00632,4.98]|24.0|\n",
      "|[6.421,0.02731,9.14]|21.6|\n",
      "|[7.185,0.02729,4.03]|34.7|\n",
      "|[6.998,0.03237,2.94]|33.4|\n",
      "|[7.147,0.06905,5.33]|36.2|\n",
      "+--------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subsetDF = (bostonFeaturizedDF\n",
    "            .limit(10)\n",
    "            .select(\"features\", \"medv\")\n",
    "           )\n",
    "\n",
    "subsetDF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sử dụng phương thức `transform` trên mô hình được huấn luyện để xem dự đoán của nó.\n",
    "\n",
    "`lrModel` là một estimator, ta có thể biến đổi dữ liệu bằng cách sử dụng phương thức `.transform()` của nó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+------------------+\n",
      "|            features|medv|        prediction|\n",
      "+--------------------+----+------------------+\n",
      "|[6.575,0.00632,4.98]|24.0| 28.85771764778442|\n",
      "|[6.421,0.02731,9.14]|21.6|25.645644850540148|\n",
      "|[7.185,0.02729,4.03]|34.7| 32.58746300992211|\n",
      "|[6.998,0.03237,2.94]|33.4| 32.24191904275642|\n",
      "|[7.147,0.06905,5.33]|36.2|31.632888345842236|\n",
      "+--------------------+----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictionDF = lrModel.transform(subsetDF)\n",
    "\n",
    "predictionDF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bây giờ, ta thử dự đoán giá nhà cho một điểm dữ liệu mới của một ngôi nhà 6 phòng ngủ (`rm = 6`), với tỷ lệ tội phạm là 3.6 (`crim = 3.6`), và tầng lớp có thu nhập thấp hơn trung bình là 12% (`lstat = 12`). Theo công thức ở trên, mô hình sẽ dự đoán giá nhà khoảng 21."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+\n",
      "|      features|        prediction|\n",
      "+--------------+------------------+\n",
      "|[6.0,3.6,12.0]|21.427061506649363|\n",
      "+--------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "data = [(Vectors.dense([6., 3.6, 12.]), )]              # Tạo new data point\n",
    "predictDF = spark.createDataFrame(data, [\"features\"])\n",
    "\n",
    "lrModel.transform(predictDF).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9. Tạo ML pipeline và đánh giá dùng phương pháp hold out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.147526277317931, 6.368200422041555, 6.398422404073777]\n",
      "('features=[7.249,0.01311,4.81], '\n",
      " 'scaledFeatures=[1.4164431814772305,-0.4648881655422324,-1.092220358196006], '\n",
      " 'label=35.4 -> prediction=31.724843080902087')\n",
      "('features=[7.135,0.01778,4.45], '\n",
      " 'scaledFeatures=[1.2499947891838228,-0.4642127043800687,-1.142381331431606], '\n",
      " 'label=32.9 -> prediction=31.358533659654878')\n",
      "('features=[6.516,0.0187,6.36], '\n",
      " 'scaledFeatures=[0.3462092205029505,-0.46407963708473876,-0.8762495012093932], '\n",
      " 'label=23.1 -> prediction=27.33261565331063')\n",
      "('features=[7.104,0.01951,8.05], '\n",
      " 'scaledFeatures=[1.2047325070689492,-0.4639624800095027,-0.6407715990756024], '\n",
      " 'label=33.0 -> prediction=29.307524854443365')\n",
      "('features=[8.034,0.02009,2.88], '\n",
      " 'scaledFeatures=[2.5626009705151724,-0.463878589758099,-1.36113890915353], '\n",
      " 'label=50.0 -> prediction=36.5698484440496')\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent = 4)\n",
    "\n",
    "# Create a LinearRegression instance. This instance is an Estimator.\n",
    "lr = LinearRegression(labelCol=\"medv\", featuresCol=\"features\")\n",
    "\n",
    "# Create a StandardScaler to normalize each feature to have zero mean and unit standard deviation\n",
    "scaler = StandardScaler(inputCol = \"features\", outputCol = \"scaledFeatures\",\n",
    "                        withStd = True, withMean = True)\n",
    "\n",
    "# Configure an ML pipeline, which consists of two stages: scaler and lr.\n",
    "pipeline = Pipeline(stages = [scaler, lr])\n",
    "\n",
    "# Specify parameters\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [1, 0.1, 0.01]) \\\n",
    "    .build()\n",
    "\n",
    "# Train/test split\n",
    "trainDF, testDF = bostonFeaturizedDF.randomSplit([.8, .2], seed = 1)\n",
    "\n",
    "# Setup TrainValidationSplit \n",
    "# A TrainValidationSplit requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n",
    "# trainRatio = 0.8: 80% of the data will be used for training, 20% for testing\n",
    "tvs = TrainValidationSplit(estimator = pipeline, \n",
    "                           estimatorParamMaps = paramGrid, \n",
    "                           evaluator = RegressionEvaluator(labelCol = \"medv\", metricName = \"rmse\"), \n",
    "                           trainRatio = 0.8)\n",
    "\n",
    "# Run cross-validation on training data, and choose the best set of parameters\n",
    "lrModel = tvs.fit(trainDF)\n",
    "\n",
    "# Print rmse on validation set for each `regParam`: 1, 0.1, 0.01\n",
    "print(lrModel.validationMetrics)\n",
    "\n",
    "# Make predictions on test data. cvModel uses the best model found (regParam = 0.1)\n",
    "prediction = lrModel.transform(testDF)\n",
    "result = prediction.select(\"features\", \"scaledFeatures\", \"medv\", \"prediction\").collect()\n",
    "\n",
    "# Print some predictions\n",
    "for row in result[0:5]:\n",
    "    pp.pprint(\"features=%s, scaledFeatures=%s, label=%s -> prediction=%s\" % \n",
    "              (row.features, row.scaledFeatures, row.medv, row.prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Câu hỏi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Câu hỏi 1**: Huấn luyện mô hình Linear Regression và dùng nó để dự đoán cho dữ liệu mới\n",
    "\n",
    "#### a. Tạo mô hình Linear Regression\n",
    "\n",
    "Tạo một mô hình linear regression mới với input là các biến `indus`, `age`, `dis`, và output là biến `medv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. Tạo biến `newFeatures` cho huấn luyện mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+------------------+\n",
      "|   crim|  zn|indus|chas|  nox|   rm| age|   dis|rad|tax|ptratio|     b|lstat|medv|       newFeatures|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+------------------+\n",
      "|0.00632|18.0| 2.31|   0|0.538|6.575|65.2|  4.09|  1|296|   15.3| 396.9| 4.98|24.0|  [2.31,65.2,4.09]|\n",
      "|0.02731| 0.0| 7.07|   0|0.469|6.421|78.9|4.9671|  2|242|   17.8| 396.9| 9.14|21.6|[7.07,78.9,4.9671]|\n",
      "|0.02729| 0.0| 7.07|   0|0.469|7.185|61.1|4.9671|  2|242|   17.8|392.83| 4.03|34.7|[7.07,61.1,4.9671]|\n",
      "|0.03237| 0.0| 2.18|   0|0.458|6.998|45.8|6.0622|  3|222|   18.7|394.63| 2.94|33.4|[2.18,45.8,6.0622]|\n",
      "|0.06905| 0.0| 2.18|   0|0.458|7.147|54.2|6.0622|  3|222|   18.7| 396.9| 5.33|36.2|[2.18,54.2,6.0622]|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "newFeatureCols = [\"indus\", \"age\", \"dis\"]\n",
    "assembler = VectorAssembler(inputCols =newFeatureCols, outputCol = \"newFeatures\")\n",
    "bostonFeaturizedDF = assembler.transform(bostonDF)\n",
    "\n",
    "bostonFeaturizedDF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. Huấn luyện mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(labelCol = \"medv\", featuresCol = \"newFeatures\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii. In kết quả của mô hình (các hệ số và $R^2$ score )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: -0.7, -0.1, -1.5\n",
      "Intercept: 43.0\n",
      "R-Squared score: 0.28545147539354365\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "lrModel = lr.fit(bostonFeaturizedDF)\n",
    "print(\"Coefficients: {0:.1f}, {1:.1f}, {2:.1f}\".format(*lrModel.coefficients))\n",
    "print(\"Intercept: {0:.1f}\".format(lrModel.intercept))\n",
    "print(\"R-Squared score: {}\".format(lrModel.summary.r2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv. Diễn giải các hệ số (`Coefficients`, `Intercept`), $R^2$ `score`, `RMSE score`, các `Standard Errors`, `t-values`, `p-values` của mô hình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE score: 5.560969336121601\n",
      "RMSE score: 7.766715476913\n",
      "Coefficient Standard Errors: [0.07389071808161014, 0.01915733859996422, 0.2771928541130852, 2.3152900779056473]\n",
      "T Values: [-9.954031888835786, -4.907552574046936, -5.573530886805179, 18.586985332722794]\n",
      "P Values: [0.0, 1.2485850908738882e-06, 4.079797522038575e-08, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "lrModelSummary = lrModel.summary\n",
    "\n",
    "print(\"MAE score: {}\".format(lrModelSummary.meanAbsoluteError))\n",
    "print(\"RMSE score: {}\".format(lrModelSummary.rootMeanSquaredError))\n",
    "print(\"Coefficient Standard Errors: \" + str(lrModelSummary.coefficientStandardErrors))\n",
    "print(\"T Values: \" + str(lrModelSummary.tValues))\n",
    "print(\"P Values: \" + str(lrModelSummary.pValues))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Sử dụng mô hình\n",
    "\n",
    "Dùng mô hình huấn luyện được để dự đoán cho các điểm dữ liệu mới có (`indus`, `age`, `dis`) lần lượt là `(11, 68, 4)`, `(6, 35, 2)`, `(19, 74, 8)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+\n",
      "|    newFeatures|        prediction|\n",
      "+---------------+------------------+\n",
      "|[11.0,68.0,4.0]|22.370810825866748|\n",
      "+---------------+------------------+\n",
      "\n",
      "+--------------+-----------------+\n",
      "|   newFeatures|       prediction|\n",
      "+--------------+-----------------+\n",
      "|[6.0,35.0,2.0]|32.24076584405401|\n",
      "+--------------+-----------------+\n",
      "\n",
      "+---------------+-----------------+\n",
      "|    newFeatures|       prediction|\n",
      "+---------------+-----------------+\n",
      "|[19.0,74.0,8.0]|9.742860699127462|\n",
      "+---------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "data = [(Vectors.dense([11, 68, 4]), )]              # Tạo new data point\n",
    "predictDF = spark.createDataFrame(data, [\"newFeatures\"])\n",
    "\n",
    "lrModel.transform(predictDF).show()\n",
    "\n",
    "data = [(Vectors.dense([6, 35, 2]), )]              # Tạo new data point\n",
    "predictDF = spark.createDataFrame(data, [\"newFeatures\"])\n",
    "\n",
    "lrModel.transform(predictDF).show()\n",
    "\n",
    "data = [(Vectors.dense([19, 74, 8]), )]              # Tạo new data point\n",
    "predictDF = spark.createDataFrame(data, [\"newFeatures\"])\n",
    "\n",
    "lrModel.transform(predictDF).show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Câu hỏi 2**: Train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiếp tục với input là các biến `indus`, `age`, `dis`, và output là biến `medv`.\n",
    "\n",
    "Giữa $80\\%$ dữ liệu để làm training set, $20\\%$ còn lại để làm test set, thế giá trị của `seed` là MSSV của bạn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số phần tử trong training set: 396\n",
      "Số phần tử trong test set: 110\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+------------------+\n",
      "|   crim|  zn|indus|chas|  nox|   rm| age|   dis|rad|tax|ptratio|     b|lstat|medv|       newFeatures|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+------------------+\n",
      "|0.00632|18.0| 2.31|   0|0.538|6.575|65.2|  4.09|  1|296|   15.3| 396.9| 4.98|24.0|  [2.31,65.2,4.09]|\n",
      "|0.01096|55.0| 2.25|   0|0.389|6.453|31.9|7.3073|  1|300|   15.3|394.72| 8.23|22.0|[2.25,31.9,7.3073]|\n",
      "|0.01301|35.0| 1.52|   0|0.442|7.241|49.3|7.0379|  1|284|   15.5|394.74| 5.49|32.7|[1.52,49.3,7.0379]|\n",
      "|0.01311|90.0| 1.22|   0|0.403|7.249|21.9|8.6966|  5|226|   17.9|395.93| 4.81|35.4|[1.22,21.9,8.6966]|\n",
      "| 0.0136|75.0|  4.0|   0| 0.41|5.888|47.6|7.3197|  3|469|   21.1| 396.9| 14.8|18.9| [4.0,47.6,7.3197]|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF, testDF = bostonFeaturizedDF.randomSplit([.8, .2], seed = 19133035)\n",
    "print(f\"Số phần tử trong training set: {trainDF.cache().count()}\")\n",
    "print(f\"Số phần tử trong test set: {testDF.cache().count()}\")\n",
    "trainDF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Thực hiện lại các bước tương tự như hương dẫn ở trên "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. Huấn luyện mô hình trên training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(labelCol = \"medv\", featuresCol = \"newFeatures\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. In kết quả của mô hình (các hệ số (`Coefficients`, `Intercept`), `RMSE score`, và $R^2$ `score`) trên training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: -0.1, 0.0, -0.0\n",
      "Intercept: 34.5\n",
      "R-Squared score: 0.7567439091524328\n",
      "RMSE score: 4.558930514386215\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "lrModel = lr.fit(trainDF)\n",
    "print(\"Coefficients: {0:.1f}, {1:.1f}, {2:.1f}\".format(*lrModel.coefficients))\n",
    "print(\"Intercept: {0:.1f}\".format(lrModel.intercept))\n",
    "print(\"R-Squared score: {}\".format(lrModel.summary.r2))\n",
    "lrModelSummary = lrModel.summary\n",
    "print(\"RMSE score: {}\".format(lrModelSummary.rootMeanSquaredError))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Đánh giá mô hình trên test set (in ra `RMSE score`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 8.1603\n"
     ]
    }
   ],
   "source": [
    "predictions = lrModel.transform(testDF)\n",
    "lr_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"medv\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = lr_evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Câu hỏi 3**: Regularization với Ridge, Lasso, và ElasticNet regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiếp tục với input là các biến `indus`, `age`, `dis`, và output là biến `medv`.\n",
    "\n",
    "Điều chỉnh các tham số `regParam` (or `lambda`, regularization parameter) và `elasticNetParam` (or `alpha`, the ElasticNet mixing parameter, in range [0, 1]. For `alpha = 0`, the penalty is an `L2 penalty`. For `alpha = 1`, it is an `L1 penalty`.) của `LinearRegression`. Xem thêm ở [đây](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.regression.LinearRegression.html#pyspark.ml.regression.LinearRegression).\n",
    "\n",
    "- `regParam = 0`: ordinary least squares (OLS)\n",
    "\n",
    "- `regParam != 0, elasticNetParam = 0`: L2 (Ridge regression)\n",
    "\n",
    "- `regParam != 0, elasticNetParam = 1`: L1 (Lasso regression)\n",
    "\n",
    "- `regParam != 0, elasticNetParam != 0`: L2 + L1 (ElasticNet regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. `regParam = 0`: ordinary least squares\n",
    "\n",
    "Thiết lập `regParam = 0` để tạo mô hình Linear Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: -0.8, -0.1, -1.6\n",
      "Intercept: 44.1\n",
      "R-Squared score: 0.31354183530490365\n",
      "MAE score: 5.600025230895622\n",
      "RMSE score: 7.658401812166801\n",
      "Coefficient Standard Errors: [0.08120270753473074, 0.021770898076406187, 0.31287336987308645, 2.6052568405716077]\n",
      "T Values: [-9.464059010148143, -4.542858348237782, -5.208679150275858, 16.943514690632025]\n",
      "P Values: [0.0, 7.399302432764543e-06, 3.0791373228922225e-07, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression(labelCol = \"medv\", featuresCol = \"newFeatures\",regParam=0.0)\n",
    "# Write your code here\n",
    "lrModel = lr.fit(trainDF)\n",
    "print(\"Coefficients: {0:.1f}, {1:.1f}, {2:.1f}\".format(*lrModel.coefficients))\n",
    "print(\"Intercept: {0:.1f}\".format(lrModel.intercept))\n",
    "print(\"R-Squared score: {}\".format(lrModel.summary.r2))\n",
    "\n",
    "lrModelSummary = lrModel.summary\n",
    "print(\"MAE score: {}\".format(lrModelSummary.meanAbsoluteError))\n",
    "print(\"RMSE score: {}\".format(lrModelSummary.rootMeanSquaredError))\n",
    "print(\"Coefficient Standard Errors: \" + str(lrModelSummary.coefficientStandardErrors))\n",
    "print(\"T Values: \" + str(lrModelSummary.tValues))\n",
    "print(\"P Values: \" + str(lrModelSummary.pValues))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. `regParam != 0, elasticNetParam = 0`: L2 (Ridge Regression)\n",
    "\n",
    "Chọn một giá trị khác 0 cho tham số `regParam` để tạo mô hình Ridge Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: -0.7, -0.1, -1.5\n",
      "Intercept: 43.3\n",
      "R-Squared score: 0.3133422845522711\n",
      "MAE score: 5.5904781983693566\n",
      "RMSE score: 7.659514865282743\n",
      "Coefficient Standard Errors: [0.08002863210800656, 0.021378839327626846, 0.3064305196126458, 2.5503396830640783]\n",
      "T Values: [-9.355477973478292, -4.475509408650018, -5.007626499602583, 16.99457613231429]\n",
      "P Values: [0.0, 1.0005179076344461e-05, 8.346942454995343e-07, 0.0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Write your code here\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr =LinearRegression(labelCol = \"medv\", featuresCol = \"newFeatures\",regParam=0.1,elasticNetParam=0.0)\n",
    "# Write your code here\n",
    "lrModel = lr.fit(trainDF)\n",
    "print(\"Coefficients: {0:.1f}, {1:.1f}, {2:.1f}\".format(*lrModel.coefficients))\n",
    "print(\"Intercept: {0:.1f}\".format(lrModel.intercept))\n",
    "print(\"R-Squared score: {}\".format(lrModel.summary.r2))\n",
    "\n",
    "lrModelSummary = lrModel.summary\n",
    "print(\"MAE score: {}\".format(lrModelSummary.meanAbsoluteError))\n",
    "print(\"RMSE score: {}\".format(lrModelSummary.rootMeanSquaredError))\n",
    "print(\"Coefficient Standard Errors: \" + str(lrModelSummary.coefficientStandardErrors))\n",
    "print(\"T Values: \" + str(lrModelSummary.tValues))\n",
    "print(\"P Values: \" + str(lrModelSummary.pValues))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. `regParam != 0, elasticNetParam = 1`: L1 (Lasso regression)\n",
    "\n",
    "Chọn một giá trị khác 0 cho tham số `regParam` và thiết lập `elasticNetParam = 1` để tạo mô hình Lasso Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: -0.7, -0.1, -0.9\n",
      "Intercept: 37.5\n",
      "R-Squared score: 0.3016884873864013\n",
      "MAE score: 5.601937338571584\n",
      "RMSE score: 7.724239163475788\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "\n",
    "# Write your code here\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr =LinearRegression(labelCol = \"medv\", featuresCol = \"newFeatures\",regParam=0.3,elasticNetParam=1)\n",
    "# Write your code here\n",
    "lrModel = lr.fit(trainDF)\n",
    "print(\"Coefficients: {0:.1f}, {1:.1f}, {2:.1f}\".format(*lrModel.coefficients))\n",
    "print(\"Intercept: {0:.1f}\".format(lrModel.intercept))\n",
    "print(\"R-Squared score: {}\".format(lrModel.summary.r2))\n",
    "\n",
    "lrModelSummary = lrModel.summary\n",
    "print(\"MAE score: {}\".format(lrModelSummary.meanAbsoluteError))\n",
    "print(\"RMSE score: {}\".format(lrModelSummary.rootMeanSquaredError))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. `regParam != 0, elasticNetParam != 0`: L2 + L1 (ElasticNet Regression)\n",
    "\n",
    "Chọn hai giá trị khác 0 cho tham số `regParam` và `elasticNetParam` để tạo mô hình ElasticNet Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: -0.7, -0.1, -1.0\n",
      "Intercept: 38.5\n",
      "R-Squared score: 0.30485310377330077\n",
      "MAE score: 5.590728765966802\n",
      "RMSE score: 7.706716889740107\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "\n",
    "# Write your code here\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr =LinearRegression(labelCol = \"medv\", featuresCol = \"newFeatures\",regParam=0.3,elasticNetParam=0.8)\n",
    "# Write your code here\n",
    "lrModel = lr.fit(trainDF)\n",
    "print(\"Coefficients: {0:.1f}, {1:.1f}, {2:.1f}\".format(*lrModel.coefficients))\n",
    "print(\"Intercept: {0:.1f}\".format(lrModel.intercept))\n",
    "print(\"R-Squared score: {}\".format(lrModel.summary.r2))\n",
    "\n",
    "lrModelSummary = lrModel.summary\n",
    "print(\"MAE score: {}\".format(lrModelSummary.meanAbsoluteError))\n",
    "print(\"RMSE score: {}\".format(lrModelSummary.rootMeanSquaredError))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e. Nhận xét kết quả của các mô hình ở a, b, c, d.\n",
    "\n",
    "- Dựa vào kết quả ta có thể thấy thuật toán ElasticNet Regression có độ chính xác thấp nhất so với 3 thuật toán trên với R-Squared score là 0.3\n",
    "\n",
    "- Mặc dù 3 thuật toán kia có độ chính xác cao nhưng nó chỉ xem xem nhau đều gần bằng 0.31. Trong đó Linear Regression có độ chính xác cao hơn 2 thuật toán kia 1 chút với R-squared score là 0.31\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Câu hỏi 4**: Tạo ML pipeline và đánh giá các mô hình dùng cross validation\n",
    "\n",
    "**Tham khảo**\n",
    "1. ML Pipeline: https://spark.apache.org/docs/latest/ml-pipeline.html\n",
    "2. ML Tuning: https://spark.apache.org/docs/latest/ml-tuning.html\n",
    "\n",
    "\n",
    "\n",
    "**Lưu ý:** \n",
    "\n",
    "- Ở câu hỏi này, bạn cần sử dụng tất cả các thuộc tính khác `medv` làm input (`features`) và `medv` làm output (`label`) để tận dụng tối đa thông tin đã có nhất có thể.\n",
    "\n",
    "- Bạn cần thiết lập các tham số `regParam` và `elasticNetParam` là một danh sách các giá trị để bao gồm các mô hình Linear Regression, Ridge Regression, Lasso Regression, và ElasticNet Regression. Mỗi tham số tối thiểu 5 giá trị khác nhau. Chú ý rằng: \n",
    "\n",
    "    - `regParam != 0` và `elasticNetParam = 0` ứng với Ridge Regression\n",
    "    \n",
    "    - `regParam != 0` và `elasticNetParam = 1` ứng với Lasso Regression\n",
    "    \n",
    "    - `regParam != 0` và `elasticNetParam != 0` ứng với ElasticNet Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+--------------------+\n",
      "|   crim|  zn|indus|chas|  nox|   rm| age|   dis|rad|tax|ptratio|     b|lstat|medv|            features|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+--------------------+\n",
      "|0.00632|18.0| 2.31|   0|0.538|6.575|65.2|  4.09|  1|296|   15.3| 396.9| 4.98|24.0|[0.00632,18.0,2.3...|\n",
      "|0.02731| 0.0| 7.07|   0|0.469|6.421|78.9|4.9671|  2|242|   17.8| 396.9| 9.14|21.6|[0.02731,0.0,7.07...|\n",
      "|0.02729| 0.0| 7.07|   0|0.469|7.185|61.1|4.9671|  2|242|   17.8|392.83| 4.03|34.7|[0.02729,0.0,7.07...|\n",
      "|0.03237| 0.0| 2.18|   0|0.458|6.998|45.8|6.0622|  3|222|   18.7|394.63| 2.94|33.4|[0.03237,0.0,2.18...|\n",
      "|0.06905| 0.0| 2.18|   0|0.458|7.147|54.2|6.0622|  3|222|   18.7| 396.9| 5.33|36.2|[0.06905,0.0,2.18...|\n",
      "+-------+----+-----+----+-----+-----+----+------+---+---+-------+------+-----+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featureCols = [ \"crim\", \"zn\",\"indus\", \"chas\",\"nox\",\"rm\",\"age\",\"dis\",\"rad\",\"tax\",\"ptratio\",\"b\",\"lstat\",]\n",
    "assembler = VectorAssembler(inputCols = featureCols, outputCol = \"features\")\n",
    "bostonFeaturizedDF = assembler.transform(bostonDF)\n",
    "\n",
    "bostonFeaturizedDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.097214856874839, 5.431574593036092, 5.4271281444813795, 5.104019078780572, 5.428179499440657, 5.097214856874839, 5.427031498011888, 5.428588095356006, 5.079313784229277, 5.122983388533588, 5.184895212138924, 5.080086719089299, 5.177909758385377, 5.079313784229277, 5.164254015452356, 5.151469314375788, 5.070973864279012, 5.074459974386994, 5.078110355025067, 5.071064041120858, 5.07774996028774, 5.070973864279012, 5.077071385239468, 5.076259094195653, 5.069925336657595, 5.069925336657595, 5.069925336657595, 5.069925336657595, 5.069925336657595, 5.069925336657595, 5.069925336657595, 5.069925336657595, 5.080123735774617, 5.129089921317742, 5.200585856972861, 5.080926293343949, 5.192305883452861, 5.080123735774617, 5.176448129669989, 5.1616813306970055, 5.098888025787442, 5.370707927780618, 5.485764907190164, 5.103112285475868, 5.482220361178015, 5.098888025787442, 5.477757505422885, 5.476642290682196, 5.083145483737551, 5.154894564455192, 5.269528477708118, 5.08422460975808, 5.255773304018753, 5.083145483737551, 5.22985113204865, 5.206035559011729, 5.097214856874839, 5.431574593036092, 5.4271281444813795, 5.104019078780572, 5.428179499440657, 5.097214856874839, 5.427031498011888, 5.428588095356006]\n",
      "('features=[0.00906,90.0,2.97,0.0,0.4,7.088,20.8,7.3073,1.0,285.0,15.3,394.72,7.85], '\n",
      " 'scaledFeatures=[-0.41332493438362383,3.342355963269905,-1.1952360370701043,-0.2592590971970519,-1.3510857815641282,1.138198756115313,-1.7394877907922275,1.7204542798732219,-0.9788180308967985,-0.736467752047462,-1.474998678494747,0.4149140229066433,-0.6817901000864749], '\n",
      " 'label=32.2 -> prediction=31.738527791657713')\n",
      "('features=[0.02009,95.0,2.68,0.0,0.4161,8.034,31.9,5.118,4.0,224.0,14.7,390.55,2.88], '\n",
      " 'scaledFeatures=[-0.4121214408441576,3.5550088707512892,-1.2372416516030853,-0.2592590971970519,-1.2106185810817662,2.488932479583392,-1.3421127143581495,0.6688034312375242,-0.6342740840211251,-1.098533794959001,-1.756198779602308,0.36937116756663213,-1.381991382606132], '\n",
      " 'label=50.0 -> prediction=43.53725327522015')\n",
      "('features=[0.02731,0.0,7.07,0.0,0.469,6.421,78.9,4.9671,2.0,242.0,17.8,396.9,9.14], '\n",
      " 'scaledFeatures=[-0.41133365994162396,-0.48539637139500796,-0.601363555741755,-0.2592590971970519,-0.7490834937825774,0.18583153248612966,0.3404664381104691,0.5963171967976909,-0.8639700486049073,-0.9916946347555959,-0.3033315905465795,0.43872299764074923,-0.5000477148851956], '\n",
      " 'label=21.6 -> prediction=24.78505365225961')\n",
      "('features=[0.02985,0.0,2.18,0.0,0.458,6.43,58.7,6.0622,3.0,222.0,18.7,394.12,5.21], '\n",
      " 'scaledFeatures=[-0.4110565181836689,-0.48539637139500796,-1.3096651249358107,-0.2592590971970519,-0.8450548729941287,0.1986820647389964,-0.38268460188668185,1.1223587828484616,-0.7491220663130163,-1.1104048127593793,0.1184685611147602,0.4083610940807422,-1.0537280046844417], '\n",
      " 'label=28.7 -> prediction=25.068256044367175')\n",
      "('features=[0.03306,0.0,5.19,0.0,0.515,6.059,37.3,4.8122,5.0,224.0,20.2,396.14,8.51], '\n",
      " 'scaledFeatures=[-0.4107062721037336,-0.48539637139500796,-0.8736758154728029,-0.2592590971970519,-0.34774863526154304,-0.3310454314625429,-1.148795109606436,0.5219095247318845,-0.519426101729234,-1.098533794959001,0.8214688138836608,0.43042262112794155,-0.5888056239369832], '\n",
      " 'label=20.6 -> prediction=22.390720101393676')\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent = 4)\n",
    "\n",
    "# Create a LinearRegression instance. This instance is an Estimator.\n",
    "lr = LinearRegression(labelCol=\"medv\", featuresCol=\"features\")\n",
    "\n",
    "# Create a StandardScaler to normalize each feature to have zero mean and unit standard deviation\n",
    "scaler = StandardScaler(inputCol = \"features\", outputCol = \"scaledFeatures\",\n",
    "                        withStd = True, withMean = True)\n",
    "\n",
    "# Configure an ML pipeline, which consists of two stages: scaler and lr.\n",
    "pipeline = Pipeline(stages = [scaler, lr])\n",
    "\n",
    "# Specify parameters\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [1, 0.1, 0.01, 0, 0.11, 0.58, 0.15, 1., ]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0, 0.01, 0.95, 0.0, 0.85, 0.75 ])\\\n",
    "    .build()\n",
    "\n",
    "# Train/test split\n",
    "trainDF, testDF = bostonFeaturizedDF.randomSplit([.8, .2], seed = 19133035)\n",
    "\n",
    "# Setup TrainValidationSplit \n",
    "# A TrainValidationSplit requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n",
    "# trainRatio = 0.8: 80% of the data will be used for training, 20% for testing\n",
    "tvs = TrainValidationSplit(estimator = pipeline, \n",
    "                           estimatorParamMaps = paramGrid, \n",
    "                           evaluator = RegressionEvaluator(labelCol = \"medv\", metricName = \"rmse\"), \n",
    "                           trainRatio = 0.8)\n",
    "\n",
    "# Run cross-validation on training data, and choose the best set of parameters\n",
    "lrModel = tvs.fit(trainDF)\n",
    "\n",
    "# Print rmse on validation set for each `regParam`: 1, 0.1, 0.01\n",
    "print(lrModel.validationMetrics)\n",
    "\n",
    "# Make predictions on test data. cvModel uses the best model found (regParam = 0.1)\n",
    "prediction = lrModel.transform(testDF)\n",
    "result = prediction.select(\"features\", \"scaledFeatures\", \"medv\", \"prediction\").collect()\n",
    "\n",
    "# Print some predictions\n",
    "for row in result[0:5]:\n",
    "    pp.pprint(\"features=%s, scaledFeatures=%s, label=%s -> prediction=%s\" % \n",
    "              (row.features, row.scaledFeatures, row.medv, row.prediction))\n",
    "bestModel=lrModel.bestModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel.bestModel.stages[1].getElasticNetParam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestModel.stages[1].getRegParam()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ff4f85d6e04298634172ac5d8264e7e9b556b95639fe52ebb9425c4d4cba0c9c"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
