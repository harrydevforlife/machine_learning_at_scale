{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5 - Clustering and Dimensionality Reduction\n",
    "\n",
    "\n",
    "- Your name: \n",
    "\n",
    "- Your student code: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Giới thiệu\n",
    "### 1.1. Khởi tạo Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "findspark.find()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count\n",
    "\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .appName(\"Clustering\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Đọc và load tập dữ liệu Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-----------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|      class|\n",
      "+------------+-----------+------------+-----------+-----------+\n",
      "|         5.1|        3.5|         1.4|        0.2|Iris-setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2|Iris-setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2|Iris-setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2|Iris-setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2|Iris-setosa|\n",
      "+------------+-----------+------------+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "irisDF = (spark.read\n",
    "          .option(\"HEADER\", True)\n",
    "          .option(\"inferSchema\", True)\n",
    "          .csv(\"./data/iris.csv\")\n",
    "         )\n",
    "\n",
    "irisDF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Tập dữ liệu Iris\n",
    "\n",
    "`sepal_length`: chiều dài đài hoa (cm)\n",
    "\n",
    "`sepal_width`: chiều rộng đài hoa (cm)\n",
    "\n",
    "`petal_length`: chiều dài cánh hoa (cm)\n",
    "\n",
    "`petal_width`: chiều rộng cánh hoa (cm)\n",
    "\n",
    "`class/label`: loại hoa\n",
    "\n",
    "![Iris dataset](./image/iris.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Xem các loại biến trong tập dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sepal_length', 'double'),\n",
       " ('sepal_width', 'double'),\n",
       " ('petal_length', 'double'),\n",
       " ('petal_width', 'double'),\n",
       " ('class', 'string')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irisDF.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Chuyển cột `class` (kiểu string) thành `label` (kiểu double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-----------+-----+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|      class|label|\n",
      "+------------+-----------+------------+-----------+-----------+-----+\n",
      "|         5.1|        3.5|         1.4|        0.2|Iris-setosa|  0.0|\n",
      "|         4.9|        3.0|         1.4|        0.2|Iris-setosa|  0.0|\n",
      "|         4.7|        3.2|         1.3|        0.2|Iris-setosa|  0.0|\n",
      "|         4.6|        3.1|         1.5|        0.2|Iris-setosa|  0.0|\n",
      "|         5.0|        3.6|         1.4|        0.2|Iris-setosa|  0.0|\n",
      "+------------+-----------+------------+-----------+-----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "class_indexer = StringIndexer(inputCol='class',outputCol='label')\n",
    "\n",
    "irisDFindexed = class_indexer.fit(irisDF).transform(irisDF)\n",
    "\n",
    "irisDFindexed.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. Biến đổi data theo định dạng của Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-----------------+-----+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|         features|label|\n",
      "+------------+-----------+------------+-----------+-----------------+-----+\n",
      "|         5.1|        3.5|         1.4|        0.2|[5.1,3.5,1.4,0.2]|  0.0|\n",
      "|         4.9|        3.0|         1.4|        0.2|[4.9,3.0,1.4,0.2]|  0.0|\n",
      "|         4.7|        3.2|         1.3|        0.2|[4.7,3.2,1.3,0.2]|  0.0|\n",
      "|         4.6|        3.1|         1.5|        0.2|[4.6,3.1,1.5,0.2]|  0.0|\n",
      "|         5.0|        3.6|         1.4|        0.2|[5.0,3.6,1.4,0.2]|  0.0|\n",
      "+------------+-----------+------------+-----------+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "vecAssembler = VectorAssembler(inputCols=['sepal_length','sepal_width','petal_length','petal_width'],\n",
    "                            outputCol='features')\n",
    "irisAssembler = vecAssembler.transform(irisDFindexed)\n",
    "\n",
    "selected_cols = ['sepal_length','sepal_width','petal_length','petal_width', 'features', 'label']\n",
    "\n",
    "irisFeaturesDF = irisAssembler.select(selected_cols)\n",
    "irisFeaturesDF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sử dụng thuật toán gom cụm Kmeans\n",
    "Tham khảo:\n",
    "\n",
    "1. [Kmeans User Guides](https://spark.apache.org/docs/latest/ml-clustering.html#k-means)\n",
    "\n",
    "2. [Kmeans API Docs](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.clustering.KMeans.html#pyspark.ml.clustering.KMeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Áp dụng thuật toán `KMeans` trên `irisFeaturesDF` với `k = 3`, `maxIter = 20`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([5.9016129 , 2.7483871 , 4.39354839, 1.43387097]), array([5.006, 3.418, 1.464, 0.244]), array([6.85      , 3.07368421, 5.74210526, 2.07105263])]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "kmeans = KMeans(k = 3, seed = 1, maxIter = 20)\n",
    "\n",
    "#  Call fit on the estimator and pass in irisFeaturesDF\n",
    "model = kmeans.fit(irisFeaturesDF)\n",
    "\n",
    "# Obtain the clusterCenters from the KMeansModel\n",
    "centers = model.clusterCenters()\n",
    "\n",
    "# Use the model to transform the DataFrame by adding cluster predictions\n",
    "transformedDF = model.transform(irisFeaturesDF)\n",
    "\n",
    "print(centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Tính giá trị [silhouette](https://en.wikipedia.org/wiki/Silhouette_(clustering)) của kết quả gom cụm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette with squared euclidean distance = 0.7354567373091194\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "evaluator = ClusteringEvaluator(metricName = \"silhouette\")\n",
    "\n",
    "silhouette = evaluator.evaluate(transformedDF)\n",
    "print(\"Silhouette with squared euclidean distance = \" + str(silhouette))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Tính F-mearure của kết quả gom cụm dùng true label\n",
    "\n",
    "Giả sử tập dữ liệu $D$ có $n$ phần tử $x_i$ được phân hoạch thành $p$ nhóm (ở đây ứng với số loài). Gọi $y_i \\in \\{1, 2, · · · , p\\}$ là nhóm thật sự (ground-truth labels) cho mỗi phần tử. Ground-truth clustering được cho bởi $T = \\{T_1, T_2, \\cdots , T_p\\}$, với $T_j$ bao gồm tất cả các phần tử có nhãn $j$, nghĩa là, $T_j = \\{ x_i \\in D | y_i = j \\}$. Mặt khác, gọi $C = \\{ C_1, C_2, \\cdots, C_k \\}$ là một kết quả gom cụm của $D$ thành $k$ cụm (cluster), qua một thuật toán gom cụm nào đó, và $\\hat{y_i} \\in \\{ 1, 2, \\cdots, k \\}$ là cluster label cho $x_i$. Ta sẽ xem $T$ là một phân hoạch chuẩn (ground-truth partitioning) và mỗi $T_i$ là một phân vùng (partition). Ta gọi $C$ là một kết quả gom cụm (clustering), với mỗi $C_i$ là một cụm (cluster). Giả sử ground truth là biết trước, một thuật toán gom cụm sẽ thực hiện gom cụm trên $D$ với số cụm chính xác, tức với $k = p$. Tuy nhiên, để giữ tính tổng quát, ta cho phép $k \\ne p$.\n",
    "\n",
    "| Clusters/Species | $T_1$ | $T_2$  | $\\cdots$ | $T_p$ |\n",
    "|---|---|---|---|---|\n",
    "| $C_1$ | $n_{11}$ | $n_{12}$ | $\\cdots$ | $n_{1p}$ |\n",
    "| $C_2$ | $n_{21}$ | $n_{22}$ | $\\cdots$ | $n_{2p}$ |\n",
    "| $\\vdots$ | $\\vdots$ | $\\vdots$ | $\\ddots$ | $\\vdots$ |\n",
    "| $C_k$ | $n_{k1}$ | $n_{k2}$ | $\\cdots$ | $n_{kp}$ |\n",
    "\n",
    "Các độ đo đánh giá kết quả gom cụm cố gắng nắm bắt mức độ mà các phần tử từ cùng một phân vùng (partition) xuất hiện trong cùng một cụm (cluster) và mức độ mà các phần tử từ các phân vùng (partition) khác nhau được nhóm thành các cụm (cluster) khác nhau. Những độ đo này dựa trên $k \\times p$ contingency table $N$ (xem bảng trên) được thành lập dựa vào một kết quả gom cụm (clustering) $C$ và một phân hoạch chuẩn (ground-truth partitioning) $T$, được định nghĩa như sau:\n",
    "\n",
    "$$N(i, j) = n_{ij} = |C_i \\cap T_j|$$\n",
    "\n",
    "- $Recall$ là tỷ lệ đối tượng cùng loài được gán cùng cụm. \n",
    "\n",
    "- $Precision$ là tỷ lệ đối tượng được gán cùng cụm thuộc cùng loài. \n",
    "\n",
    "- $F{\\text -}measure$ là một độ đo cân bằng giữa $Precision$ và $Recall$ và được tính bằng trung bình điều hòa giữa $Precision$ và $Recall$. Đây là một độ đo thường được sử dụng để so sánh các thuật toán gom cụm với nhau.\n",
    "\n",
    "Các độ đo $Precision$, $Recall$, và $F{\\text -}measure$ được tính từ contingency table ở trên dùng các công thức sau:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "precision = \\frac{{\\sum\\limits_{i = 1}^k {\\mathop {{\\rm{max}}}\\limits_{j \\in \\left\\{ {1, \\ldots p} \\right\\}} \\{n_{ij}\\} } }}{{\\sum\\limits_{i = 1}^k {\\sum\\limits_{j = 1}^p {n_{ij} } } }}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "recall = \\frac{{\\sum\\limits_{j = 1}^p {\\mathop {{\\rm{max}}}\\limits_{i \\in \\left\\{ {1, \\ldots ,k} \\right\\}} \\{n_{ij}\\} } }}{{\\sum\\limits_{i = 1}^k {\\sum\\limits_{j = 1}^p {n_{ij} } } }}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "F{\\text -}measure = \\frac{{2 \\cdot precision \\cdot recall}}{{precision + recall}}\n",
    "\\end{split}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viết code của bạn ở đây\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Áp dụng PCA\n",
    "\n",
    "Tham khảo:\n",
    "\n",
    "1. [PCA User Guides](https://spark.apache.org/docs/latest/ml-features.html#pca)\n",
    "\n",
    "2. [PCA API Docs](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.feature.PCA.html#pyspark.ml.feature.PCA)\n",
    "\n",
    "### 3.1. Thực hiện thu giảm chiều trên `features` dùng PCA, với `k = 2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------------------------------+\n",
      "|features         |pcaFeatures                             |\n",
      "+-----------------+----------------------------------------+\n",
      "|[5.1,3.5,1.4,0.2]|[-2.8271359726790286,-5.641331045573357]|\n",
      "|[4.9,3.0,1.4,0.2]|[-2.7959524821488464,-5.145166883252942]|\n",
      "|[4.7,3.2,1.3,0.2]|[-2.62152355816506,-5.17737812120394]   |\n",
      "|[4.6,3.1,1.5,0.2]|[-2.764905900474242,-5.003599415056977] |\n",
      "|[5.0,3.6,1.4,0.2]|[-2.782750115951662,-5.648648294377423] |\n",
      "+-----------------+----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import PCA\n",
    "\n",
    "pca = PCA(k = 2, inputCol = \"features\", outputCol = \"pcaFeatures\")\n",
    "pcaModel = pca.fit(irisFeaturesDF)\n",
    "\n",
    "irisPCA = pcaModel.transform(irisFeaturesDF).select(\"features\", \"pcaFeatures\")\n",
    "irisPCA.show(5, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Áp dụng k-means trên `pcaFeatures` được tạo ra bởi PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-6.17577661, -4.98443152]), array([-2.87050234, -5.50524368]), array([-7.85779422, -5.58707828])]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "kmeans = KMeans(k = 3, seed = 1, maxIter = 20, featuresCol = 'pcaFeatures')\n",
    "\n",
    "#  Call fit on the estimator and pass in irisPCA\n",
    "kMeansModel = kmeans.fit(irisPCA)\n",
    "\n",
    "# Obtain the clusterCenters from the kMeansModel\n",
    "centers = kMeansModel.clusterCenters()\n",
    "\n",
    "# Use the model to transform the DataFrame by adding cluster predictions\n",
    "transformedIrisPCA = kMeansModel.transform(irisPCA)\n",
    "\n",
    "print(centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Tính giá trị [silhouette](https://en.wikipedia.org/wiki/Silhouette_(clustering)) của kết quả gom cụm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette with squared euclidean distance = 0.7342113066202725\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "evaluator = ClusteringEvaluator(metricName = \"silhouette\")\n",
    "\n",
    "silhouette = evaluator.evaluate(transformedIrisPCA)\n",
    "print(\"Silhouette with squared euclidean distance = \" + str(silhouette))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Tính F-mearure của kết quả gom cụm dùng true label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viết code của bạn ở đây\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Áp dụng `Kmeans` với tập dữ liệu `iris`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Tạo `features` column cho tập dữ liệu `iris` chỉ dùng 2 thuộc tính `sepal_length` và `sepal_width`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viết code của bạn ở đây\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Áp dụng `Kmeans` cho tập dữ liệu `iris` trên `features` vừa tạo \n",
    "\n",
    "Thiết lập các giá trị siêu tham số `k = 3`, `seed = 1`, và `maxIter = 20`. \n",
    "\n",
    "Tham khảo document về `Kmeans` của Spark ở [Kmeans](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.clustering.KMeans.html#pyspark.ml.clustering.KMeans)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viết code của bạn ở đây\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Tính giá trị `silhouette` của kết quả gom cụm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viết code của bạn ở đây\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Tính F-mearure của kết quả gom cụm dùng true label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viết code của bạn ở đây\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Áp dụng thuật toán `KMeans` trên `features` đã tạo với `k = 3`, và `maxIter` thay đổi. In ra các centers và chỉ số `silhouette` cho từng kết quả gom cụm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viết code của bạn ở đây\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Trực quan hóa kết quả gom cụm dùng thư viện `matplotlib`. \n",
    "Tham khảo [python-machine-learning-book-chapter10-notebook](https://github.com/rasbt/machine-learning-book/blob/main/ch10/ch10.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viết code của bạn ở đây\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Áp dụng `BisectingKMeans` trên tập dữ liệu `iris`\n",
    "\n",
    "Thực lại các bước trên tập dữ liệu iris với thuật toán BisectingKMeans.\n",
    "\n",
    "Tham khảo: \n",
    "\n",
    "1. [BisectingKMeans User Guides](https://spark.apache.org/docs/latest/ml-clustering.html#bisecting-k-means)\n",
    "\n",
    "2. [BisectingKMeans API Documentations](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.clustering.BisectingKMeans.html#pyspark.ml.clustering.BisectingKMeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bisecting Kmeans** là một thuật toán gọm cụm thuộc nhóm **hierarchical clustering**. Khác với thuật toán **AGNES (agglomerative nesting)** tiếp cận theo hướng **bottom-up**, thuật toán **Bisecting Kmeans** tiếp cận theo hướng **top-down**.\n",
    "\n",
    "**Ý tưởng của thuật toán Bisecting Kmeans**\n",
    "\n",
    "Thuật toán khởi đầu bằng việc xem tất cả các điểm dữ liệu thuộc cùng một cụm và sau đó tiến hành như sau:\n",
    "\n",
    "1. Chọn một cụm để tách\n",
    "2. Tách cụm đã chọn thành 2 `sub-clusters` dùng thuật toán `K-means`. (`bisecting step`) \n",
    "3. Lặp lại bước 2 (`bisecting step`) `iter` lần và chọn ra phép tách tạo ra các cụm có `độ tương tự tổng thể` cao nhất.\n",
    "4. Lặp lại bước 1, 2, và 3 cho đến khi đạt được số cụm mong muốn. \n",
    "\n",
    "- Có nhiều cách khác nhau để **chọn cụm để tách** (bước 1). Ta có thể chọn cụm có kích cỡ lớn nhất (nhiều phần tử nhất) ở mỗi bước, hoặc chọn cụm có độ tương tự tổng thể nhỏ nhất, hoặc chọn cụm dùng cả hai tiêu chí về kích cỡ và độ tương tự tổng thể.\n",
    "\n",
    "- `Độ tương tự tổng thể` (`overall similarity`) của một cụm được tính bằng độ tương tự trung bình của các cặp phần tử trong cùng một cụm (`pairwise similarity`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viết code của bạn ở đây\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Áp dụng `GaussianMixture` trên tập dữ liệu `iris`\n",
    "\n",
    "Thực lại các bước trên tập dữ liệu iris với thuật toán GaussianMixture.\n",
    "\n",
    "Tham khảo: \n",
    "\n",
    "1. [GaussianMixture User Guides](https://spark.apache.org/docs/latest/ml-clustering.html#gaussian-mixture-model-gmm)\n",
    "\n",
    "2. [GaussianMixture API Documentations](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.clustering.GaussianMixture.html#pyspark.ml.clustering.GaussianMixture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gaussian Mixture Model** là một trường hợp đặt biệt của [**Mixture Model**](https://en.wikipedia.org/wiki/Mixture_model). Mô hình hỗn hợp (mixture model) là một mô hình xác suất biểu diễn cho sự hiện diện của các nhóm con trong một tổng thể. Một mô hình hỗn hợp tương ứng với phân bố hỗn hợp (mixture distribution) biểu diễn phân phối xác suất của các phần tử trong một tổng thể.\n",
    "\n",
    "Mixture model thuộc lớp các `mô hình sinh` (`generative model`). `Mô hình sinh` dựa trên giả định dữ liệu được sinh từ một mô hình ẩn bên dưới với các tham số. Ta cần tìm cách ước lượng các tham số sao cho nó cực đại hóa xác suất sinh ra dữ liệu. `Mô hình hỗn hợp Gauss` (`Gaussian mixture model`) giả định rằng dữ liệu được sinh từ một tổ hợp các phân bố Gauss. Ta cần ước lượng các tham số của mô hình, tức $\\theta = \\{(\\mu_i, \\sigma_i)\\}_{i=1..k}$ (mỗi phân bố Gauss được biểu diễn bởi một cặp $(\\mu_i, \\sigma_i)$), sao cho xác xuất sinh ra tập dữ liệu $D = \\{x_1, x_2, \\cdots, x_n\\}$, $P(D | \\theta)$, là lớn nhất. Thuật toán `Expectation-Maximization` (`EM`) thường được sử dụng để ước lượng các tham số cho mô hình `Gaussian mixture model`. Tham khảo thêm [Gaussian mixture model](https://brilliant.org/wiki/gaussian-mixture-model/).\n",
    "\n",
    "Khác với các thuật toán `gom cụm cứng` (`hard clustering`), Gaussian mixture model được xem là một thuật toán `gom cụm mềm` (`soft clustring`). Mỗi phần tử có thể thuộc nhiều cụm ứng với xác suất khác nhau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viết code của bạn ở đây\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "ff4f85d6e04298634172ac5d8264e7e9b556b95639fe52ebb9425c4d4cba0c9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
